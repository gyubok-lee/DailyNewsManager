{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 부족으로 실패\n",
    "### 학습 데이터가 충분하다면 나중에 다시 시도할만함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------뉴스 기사 스크랩을 실행합니다----------\n",
      "\n",
      "정치 뉴스 기사 크롤링 완료\n",
      "경제 뉴스 기사 크롤링 완료\n",
      "사회 뉴스 기사 크롤링 완료\n",
      "생활 뉴스 기사 크롤링 완료\n",
      "세계 뉴스 기사 크롤링 완료\n",
      "과학 뉴스 기사 크롤링 완료\n"
     ]
    }
   ],
   "source": [
    "import scraper \n",
    "\n",
    "scraps = scraper.news_scraper()\n",
    "news_list = scraps.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>분야</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'위안부 다큐' 英감독 \"더 많이 알려져야 하는 보편적 문제\"</td>\n",
       "      <td>기사내용 요약'이용수 할머니 밀착취재 다큐' 낸시 로버츠 英감독이 할머니 \"위안부 ...</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“조국·이재명 가족이라면?”…이재명 ‘김건희 무혐의’ 비판 댓글 공유</td>\n",
       "      <td>이재명 더불어민주당 대선후보가 6일 서울 여의도 더불어민주당 당사에서 열린 소상공인...</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>닻 올린 '김종인 원톱' 선대위…\"민생·정의 회복\"</td>\n",
       "      <td>'윤석열 선대위'의 키를 거머쥔 김종인 위원장, 한층 '독해진' 어조로 문재인 정부...</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>민주, 개발이익환수법 당론 채택…이재명 \"169석 힘 보여달라\" 편지</td>\n",
       "      <td>민주당이 정책 의원총회를 열어 개발이익환수법을 당론으로 추진하기로 했습니다. 대장동...</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김병준 \"자유·민주 죽인 文, 더 한 이재명 막아야…그 국가주의·포퓰리즘 끝은 파멸\"</td>\n",
       "      <td>국힘 선대위 출범식서 연설 \"시장·개인자유 확대 '자유주의 철학'이 사회 문제 해법...</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>임혜숙 장관, OECD 회원국에 '과학기술 기반 미래예측' 제안</td>\n",
       "      <td>임혜숙 과학기술정보통신부 장관이 6일 OECD 과학기술정책위원회 콘퍼런스 고위급회담...</td>\n",
       "      <td>과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“초봉 6500만원 준다고 하니…우르르” 난리난 ‘이곳’</td>\n",
       "      <td>김용현 당근마켓 공동대표이런 상황에서 ‘업계 최고 대우’를 내건 당근마켓이 승부수는...</td>\n",
       "      <td>과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>임혜숙 장관, “미래 예측을 통한 국가·사회 문제해결” 강조</td>\n",
       "      <td>OECD 과학기술정책위원회 컨퍼런스 고위급 회담 참가임혜숙 과학기술정보통신부 장관이...</td>\n",
       "      <td>과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>임혜숙 과기장관, OECD 컨퍼런스서 포용적 기술전환 방안 제시</td>\n",
       "      <td>기사내용 요약과기장관, 'OECD 과학기술정책위원회 컨퍼런스' 온라인 참석\"미래 예...</td>\n",
       "      <td>과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>임혜숙 장관 \"포용적 기술 전환, 과학기술 기반의 미래 예측이 필수적\"</td>\n",
       "      <td>OECD 과학기술정책위서 포용적 기술 전환 방안 제시임혜숙 과학기술정보통신부 장관이...</td>\n",
       "      <td>과학</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0                '위안부 다큐' 英감독 \"더 많이 알려져야 하는 보편적 문제\"   \n",
       "1            “조국·이재명 가족이라면?”…이재명 ‘김건희 무혐의’ 비판 댓글 공유   \n",
       "2                      닻 올린 '김종인 원톱' 선대위…\"민생·정의 회복\"   \n",
       "3            민주, 개발이익환수법 당론 채택…이재명 \"169석 힘 보여달라\" 편지   \n",
       "4   김병준 \"자유·민주 죽인 文, 더 한 이재명 막아야…그 국가주의·포퓰리즘 끝은 파멸\"   \n",
       "..                                              ...   \n",
       "15              임혜숙 장관, OECD 회원국에 '과학기술 기반 미래예측' 제안   \n",
       "16                  “초봉 6500만원 준다고 하니…우르르” 난리난 ‘이곳’   \n",
       "17                임혜숙 장관, “미래 예측을 통한 국가·사회 문제해결” 강조   \n",
       "18              임혜숙 과기장관, OECD 컨퍼런스서 포용적 기술전환 방안 제시   \n",
       "19          임혜숙 장관 \"포용적 기술 전환, 과학기술 기반의 미래 예측이 필수적\"   \n",
       "\n",
       "                                             contents  분야  \n",
       "0   기사내용 요약'이용수 할머니 밀착취재 다큐' 낸시 로버츠 英감독이 할머니 \"위안부 ...  정치  \n",
       "1   이재명 더불어민주당 대선후보가 6일 서울 여의도 더불어민주당 당사에서 열린 소상공인...  정치  \n",
       "2   '윤석열 선대위'의 키를 거머쥔 김종인 위원장, 한층 '독해진' 어조로 문재인 정부...  정치  \n",
       "3   민주당이 정책 의원총회를 열어 개발이익환수법을 당론으로 추진하기로 했습니다. 대장동...  정치  \n",
       "4   국힘 선대위 출범식서 연설 \"시장·개인자유 확대 '자유주의 철학'이 사회 문제 해법...  정치  \n",
       "..                                                ...  ..  \n",
       "15  임혜숙 과학기술정보통신부 장관이 6일 OECD 과학기술정책위원회 콘퍼런스 고위급회담...  과학  \n",
       "16  김용현 당근마켓 공동대표이런 상황에서 ‘업계 최고 대우’를 내건 당근마켓이 승부수는...  과학  \n",
       "17  OECD 과학기술정책위원회 컨퍼런스 고위급 회담 참가임혜숙 과학기술정보통신부 장관이...  과학  \n",
       "18  기사내용 요약과기장관, 'OECD 과학기술정책위원회 컨퍼런스' 온라인 참석\"미래 예...  과학  \n",
       "19  OECD 과학기술정책위서 포용적 기술 전환 방안 제시임혜숙 과학기술정보통신부 장관이...  과학  \n",
       "\n",
       "[115 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = news_list[0]\n",
    "df['분야'] = '정치'\n",
    "secs = ['정치','경제', '사회', '생활', '세계', '과학']\n",
    "for i in range(1,len(news_list)):\n",
    "    now = news_list[i]\n",
    "    now['분야'] = secs[i]\n",
    "    df = pd.concat([df,now], axis = 0)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>분야</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>음압 병동 현장 점검 나선 이재명</td>\n",
       "      <td>인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...</td>\n",
       "      <td>정치</td>\n",
       "      <td>sostoken 음압 병동 현장 점검 나선 이재명</td>\n",
       "      <td>음압 병동 현장 점검 나선 이재명 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이재명 인천 의료 원 음압 병동 방문</td>\n",
       "      <td>인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...</td>\n",
       "      <td>정치</td>\n",
       "      <td>sostoken 이재명 인천 의료 원 음압 병동 방문</td>\n",
       "      <td>이재명 인천 의료 원 음압 병동 방문 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>의료 진 격려 하는 이재명</td>\n",
       "      <td>인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...</td>\n",
       "      <td>정치</td>\n",
       "      <td>sostoken 의료 진 격려 하는 이재명</td>\n",
       "      <td>의료 진 격려 하는 이재명 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인천 의료 원 음압 병동 방문 이재명 대선 후보</td>\n",
       "      <td>인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...</td>\n",
       "      <td>정치</td>\n",
       "      <td>sostoken 인천 의료 원 음압 병동 방문 이재명 대선 후보</td>\n",
       "      <td>인천 의료 원 음압 병동 방문 이재명 대선 후보 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>인천 의료 원 찾은 이재명 지지자 들 함께</td>\n",
       "      <td>인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...</td>\n",
       "      <td>정치</td>\n",
       "      <td>sostoken 인천 의료 원 찾은 이재명 지지자 들 함께</td>\n",
       "      <td>인천 의료 원 찾은 이재명 지지자 들 함께 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>카카오 렌터카 연합 회 맞 손 이 달 중 렌터카 서비스 시작</td>\n",
       "      <td>박주연 기자 카카오 모빌리티 중소 렌터카 사업자 들 손잡고 이 달 중 카카오 렌터카...</td>\n",
       "      <td>과학</td>\n",
       "      <td>sostoken 카카오 렌터카 연합 회 맞 손 이 달 중 렌터카 서비스 시작</td>\n",
       "      <td>카카오 렌터카 연합 회 맞 손 이 달 중 렌터카 서비스 시작 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>한미 약품 신약 2 개 美 FDA 승인 기대</td>\n",
       "      <td>대한민국 바이오 투자 콘퍼런스 국내 제약 바이오 업체 총 출동 2021 대한민국 바...</td>\n",
       "      <td>과학</td>\n",
       "      <td>sostoken 한미 약품 신약 2 개 美 FDA 승인 기대</td>\n",
       "      <td>한미 약품 신약 2 개 美 FDA 승인 기대 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>방심위 ‘ 아이돌 학교 과징금 철퇴 ‘ 김어준 뉴스 공장 은 권고</td>\n",
       "      <td>방송통신 심의 위원회 전체 회의 전경 방심위 제공 방송통신 심의 위원회 6일 서울 ...</td>\n",
       "      <td>과학</td>\n",
       "      <td>sostoken 방심위 ‘ 아이돌 학교 과징금 철퇴 ‘ 김어준 뉴스 공장 은 권고</td>\n",
       "      <td>방심위 ‘ 아이돌 학교 과징금 철퇴 ‘ 김어준 뉴스 공장 은 권고 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>네이버 클라우드 게임 리포트 日 서비스 돌입</td>\n",
       "      <td>관련 이미지 네이버 클라우드 제공 네이버 클라우드 게임 분석 솔루션 일본 진출 한다...</td>\n",
       "      <td>과학</td>\n",
       "      <td>sostoken 네이버 클라우드 게임 리포트 日 서비스 돌입</td>\n",
       "      <td>네이버 클라우드 게임 리포트 日 서비스 돌입 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>알테오 젠 무역 날 2000만 불 수출 탑 수상</td>\n",
       "      <td>기술 수출 액   2000만 달라  돌파 해 알테오 젠 올해 2200만달러 이상 기...</td>\n",
       "      <td>과학</td>\n",
       "      <td>sostoken 알테오 젠 무역 날 2000만 불 수출 탑 수상</td>\n",
       "      <td>알테오 젠 무역 날 2000만 불 수출 탑 수상 eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                     음압 병동 현장 점검 나선 이재명   \n",
       "1                   이재명 인천 의료 원 음압 병동 방문   \n",
       "2                         의료 진 격려 하는 이재명   \n",
       "3             인천 의료 원 음압 병동 방문 이재명 대선 후보   \n",
       "4                인천 의료 원 찾은 이재명 지지자 들 함께   \n",
       "..                                   ...   \n",
       "10     카카오 렌터카 연합 회 맞 손 이 달 중 렌터카 서비스 시작   \n",
       "11              한미 약품 신약 2 개 美 FDA 승인 기대   \n",
       "12  방심위 ‘ 아이돌 학교 과징금 철퇴 ‘ 김어준 뉴스 공장 은 권고   \n",
       "13              네이버 클라우드 게임 리포트 日 서비스 돌입   \n",
       "14            알테오 젠 무역 날 2000만 불 수출 탑 수상   \n",
       "\n",
       "                                             contents  분야  \\\n",
       "0   인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...  정치   \n",
       "1   인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...  정치   \n",
       "2   인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...  정치   \n",
       "3   인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...  정치   \n",
       "4   인천 뉴스 1 국회 사 진취 재단 이재명 더불어 민주당 대선 후보 6일 오후 인천 ...  정치   \n",
       "..                                                ...  ..   \n",
       "10  박주연 기자 카카오 모빌리티 중소 렌터카 사업자 들 손잡고 이 달 중 카카오 렌터카...  과학   \n",
       "11  대한민국 바이오 투자 콘퍼런스 국내 제약 바이오 업체 총 출동 2021 대한민국 바...  과학   \n",
       "12  방송통신 심의 위원회 전체 회의 전경 방심위 제공 방송통신 심의 위원회 6일 서울 ...  과학   \n",
       "13  관련 이미지 네이버 클라우드 제공 네이버 클라우드 게임 분석 솔루션 일본 진출 한다...  과학   \n",
       "14  기술 수출 액   2000만 달라  돌파 해 알테오 젠 올해 2200만달러 이상 기...  과학   \n",
       "\n",
       "                                    decoder_input  \\\n",
       "0                     sostoken 음압 병동 현장 점검 나선 이재명   \n",
       "1                   sostoken 이재명 인천 의료 원 음압 병동 방문   \n",
       "2                         sostoken 의료 진 격려 하는 이재명   \n",
       "3             sostoken 인천 의료 원 음압 병동 방문 이재명 대선 후보   \n",
       "4                sostoken 인천 의료 원 찾은 이재명 지지자 들 함께   \n",
       "..                                            ...   \n",
       "10     sostoken 카카오 렌터카 연합 회 맞 손 이 달 중 렌터카 서비스 시작   \n",
       "11              sostoken 한미 약품 신약 2 개 美 FDA 승인 기대   \n",
       "12  sostoken 방심위 ‘ 아이돌 학교 과징금 철퇴 ‘ 김어준 뉴스 공장 은 권고   \n",
       "13              sostoken 네이버 클라우드 게임 리포트 日 서비스 돌입   \n",
       "14            sostoken 알테오 젠 무역 날 2000만 불 수출 탑 수상   \n",
       "\n",
       "                                   decoder_target  \n",
       "0                     음압 병동 현장 점검 나선 이재명 eostoken  \n",
       "1                   이재명 인천 의료 원 음압 병동 방문 eostoken  \n",
       "2                         의료 진 격려 하는 이재명 eostoken  \n",
       "3             인천 의료 원 음압 병동 방문 이재명 대선 후보 eostoken  \n",
       "4                인천 의료 원 찾은 이재명 지지자 들 함께 eostoken  \n",
       "..                                            ...  \n",
       "10     카카오 렌터카 연합 회 맞 손 이 달 중 렌터카 서비스 시작 eostoken  \n",
       "11              한미 약품 신약 2 개 美 FDA 승인 기대 eostoken  \n",
       "12  방심위 ‘ 아이돌 학교 과징금 철퇴 ‘ 김어준 뉴스 공장 은 권고 eostoken  \n",
       "13              네이버 클라우드 게임 리포트 日 서비스 돌입 eostoken  \n",
       "14            알테오 젠 무역 날 2000만 불 수출 탑 수상 eostoken  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def cleansing(x):\n",
    "    tokens = okt.pos(x)\n",
    "    result = []\n",
    "    for i in tokens :\n",
    "        if (i[1] != 'Punctuation') and (i[1] != 'Josa') and(i[1]!= 'KoreanParticle'):\n",
    "            result.append(i[0])\n",
    "            \n",
    "    return ' '.join(result)\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x : cleansing(x))\n",
    "df['contents'] = df['contents'].apply(lambda x : cleansing(x))\n",
    "\n",
    "df['decoder_input'] = df['title'].apply(lambda x : 'sostoken '+ x)\n",
    "df['decoder_target'] = df['title'].apply(lambda x : x + ' eostoken')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(df['contents'])\n",
    "decoder_input = np.array(df['decoder_input'])\n",
    "decoder_target = np.array(df['decoder_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 85 82 91 47 21 93 40 63 14 86 32 84 52 34  2 28 92 12 78 81 46 42 67\n",
      " 61 11 68 71 10 15 31 64 83 74  1  3 97 17 57 19  0  9 41 75 69 62 29 27\n",
      " 54 37 33 20 25 96 88 79 77 36  4 24 23 90 50 56 16 60 66  6 72 22  7 76\n",
      "  8 39 38 89 13 44 73 49 94 35 26 80 59 48 95 70 65 87 45 18 55 43 58 53\n",
      " 30 51]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 2\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 2 #int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 96\n",
      "훈련 레이블의 개수 : 96\n",
      "테스트 데이터의 개수 : 2\n",
      "테스트 레이블의 개수 : 2\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 6932\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 3412\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 3520\n",
      "단어 집합에서 희귀 단어의 비율: 49.221004039238316\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 11.616901024820402\n"
     ]
    }
   ],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 6000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 125, 64, 2217, 392, 3, 677, 2, 430, 1299, 1300, 2218, 3, 1660, 274, 1301, 1302, 235, 918, 919, 2219, 531, 1302, 235, 64, 1080, 483, 1081, 50, 56, 32, 920, 169, 431, 125, 64, 35, 678, 532, 1661, 320, 678, 532, 796, 74, 192, 354, 921, 104, 1303, 321, 6, 20, 922, 50, 56, 32, 920, 295, 2, 74, 192, 354, 25, 1082, 1304, 64, 182, 12, 533, 322, 3, 51, 679, 432, 4, 220, 1662, 139, 50, 56, 32, 125, 64, 2220, 61, 7, 236, 392, 432, 235, 296, 295, 2, 2221, 221, 170, 1663, 237, 140, 50, 56, 32, 125, 64, 107, 14, 183, 1664, 104, 2222, 50, 56, 32, 140, 680, 681, 21, 64, 171, 2223, 97, 74, 192, 5, 393, 6, 3, 33, 432, 235, 296, 5, 113, 50, 56, 32, 923, 169, 431, 125, 64, 35, 678, 532, 1305, 79, 532, 133, 74, 192, 354, 921, 104, 1083, 1084, 6, 484, 50, 56, 32, 1665, 2224, 184, 2, 50, 56, 32, 678, 532, 79, 74, 192, 354, 64, 171, 534, 2225, 104, 1085, 605, 6, 1666, 3, 18, 2, 4, 107, 14, 4, 57, 206, 2226, 74, 8, 104, 2227, 355, 356, 3, 21, 1, 4, 69, 74, 8, 104, 2228, 97, 1306, 394, 222, 50, 56, 32, 86, 2229, 2230, 682, 2231, 126, 1, 1307, 2, 183, 1308, 3, 2232, 2, 74, 192, 3, 235, 296, 797, 2, 50, 56, 32, 140, 74, 192, 104, 1083, 1084, 1309, 39, 798, 12, 533, 11, 3, 51, 679, 1310, 1311, 237, 207, 50, 56, 32, 125, 64, 35, 183, 2233, 2234, 104, 169, 431, 1086, 79, 799, 2235, 355, 1309, 74, 192, 800, 64, 171, 534, 5, 393, 1667, 164, 1311, 207, 169, 431, 1087, 2236, 2, 50, 56, 32, 924, 275, 48, 237, 183, 1668, 125, 64, 94, 323, 208, 254, 683, 70, 3, 18, 2, 1312, 6, 237, 98, 134, 1088, 10, 357, 172, 8, 2237, 3, 13, 70, 50, 56, 32, 140, 918, 919, 2238, 1089, 183, 1090, 39, 801, 2, 1089, 2239, 7, 2240, 395, 52, 2241, 2242, 67, 324, 134, 10, 6, 3, 4, 141, 2, 125, 183, 2243, 126, 114, 237, 4, 2244, 1313, 14, 2245, 2246, 925, 6, 2247, 2248, 3, 13, 2249, 1, 237, 4, 50, 56, 32, 125, 64, 35, 183, 2250, 104, 485, 105, 165, 50, 56, 32, 140, 1090, 64, 926, 94, 323, 1669, 297, 69, 1670, 2251, 173, 927, 50, 56, 32, 140, 125, 64, 926, 94, 323, 802, 1091, 2252, 797, 1092, 535, 928, 1314, 2253, 297, 2254, 2255, 164, 50, 56, 32, 923, 2, 1314, 183, 2256, 1315, 170, 1671, 433, 170, 48, 323, 298, 114, 68, 3, 51, 104, 2257, 434, 222, 235, 296, 797, 2, 2258, 170, 237, 4, 183, 1308, 1316, 173, 1315, 170, 5, 48, 2259, 2260, 323, 298, 12, 67, 2261, 3, 51, 299, 1093, 50, 56, 32, 920, 295, 125, 74, 192, 5, 929, 1304, 64, 182, 12, 533, 2262, 606, 2263, 68, 435, 607, 235, 358, 9, 64, 926, 94, 323, 208, 1317, 355, 50, 56, 32, 140, 125, 64, 930, 12, 67, 684, 299, 1, 2264, 58, 2265, 359, 235, 2266, 51, 2, 50, 56, 32, 140, 74, 192, 5, 536, 64, 171, 534, 396, 6, 608, 125, 64, 930, 12, 67, 2267, 1094, 6, 1672, 3, 18, 2, 50, 685, 430, 686, 5, 1673, 114, 50, 56, 32, 140, 125, 64, 397, 2268, 1300, 1318, 6, 1095, 3, 13, 360, 1, 361, 30, 687, 2269, 1674, 2270, 50, 685, 430, 50, 56, 32, 125, 64, 397, 79, 2271, 1675, 2272, 4, 57, 50, 685, 2273, 2274, 688, 193, 687, 325, 436, 114, 115, 537, 127, 1299, 171, 30, 1319, 108, 23, 99, 50, 685, 255, 1320, 209, 326, 803, 1096, 2275, 209, 326, 803, 98, 255, 1320, 1306, 394, 222, 86, 1097, 804, 609, 31, 223, 26, 437, 100], [], [55, 1676, 2276, 1677, 2277, 1321, 194, 538, 1678, 610, 1322, 2278, 3521, 80, 2279, 2280, 1323, 151, 539, 256, 17, 3522, 327, 1679, 135, 1676, 2276, 1677, 931, 1324, 2281, 538, 109, 2282, 3523, 1323, 2283, 538, 610, 1678, 1322, 2284, 3524, 610, 3525, 1322, 2285, 80, 3526, 3527, 3528, 2286, 2283, 3529, 2287, 76, 438, 1325, 40, 151, 276, 174, 1098, 3530, 76, 2288, 539, 2289, 1680, 3531, 1326, 174, 109, 151, 40, 2290, 16, 438, 2291, 17, 1327, 2284, 3532, 135, 1328, 76, 438, 3533, 151, 135, 3534, 1681, 328, 362, 3535, 300, 40, 17, 1099, 109, 1100, 1682, 40, 1329, 195, 438, 1683, 3536, 3537, 238, 44, 3538, 2292, 151, 1325, 932, 438, 194, 1330, 40, 174, 3539, 1331, 1684, 151, 3540, 2293, 87, 398, 17, 1330, 40, 174, 2285, 109, 3541, 151, 539, 1325, 115, 399, 438, 2294, 3542, 363, 1100, 1682, 40, 175, 175, 438, 194, 2295, 300, 17, 151, 539, 135, 689, 1681, 276, 362, 17, 933, 1101, 17, 1099, 109, 1100, 151, 3543, 115, 438, 2296, 2297, 2286, 1102, 151, 135, 2298, 1681, 1325, 1103, 59, 438, 2299, 363, 1100, 1682, 40, 195, 16, 438, 194, 3544, 300, 3545, 362, 805, 3546, 3547, 194, 3548, 3549, 2300, 44, 2301, 3550, 2302, 2303, 2279, 2280, 3551, 3552, 610, 1102, 151, 135, 3553, 2304, 3554, 3555, 3556, 2305, 1098, 17, 1330, 40, 2306, 806, 3557, 300, 256, 174, 2307, 17, 2308, 1685, 3558, 610, 1322, 109, 151, 2309, 3559, 300, 256, 174, 80, 3560, 1678, 610, 109, 2310, 3561, 300, 3562, 1679, 362, 2311, 327, 17, 540, 3563, 3564, 690, 17, 1686, 3565, 806, 1679, 135, 1331, 1332, 931, 2277, 151, 1333, 805, 3566, 2311, 327, 1104, 1334, 2312, 44, 3567, 1687, 1688, 2, 151, 135, 1331, 1332, 276, 174, 2310, 194, 2313, 3568, 1689, 44, 1326, 174, 3, 329, 807, 3569, 3570, 691, 2314, 398, 3571, 3572, 1690, 2, 55, 3573, 87, 17, 3574, 1691, 3575, 17, 610, 1683, 44, 2281, 3576, 2, 538, 3577, 151, 135, 931, 1324, 2294, 808, 1334, 1333, 55, 3578, 3579, 87, 2299, 1100, 1692, 3, 2300, 44, 2302, 2303, 3580, 808, 1323, 1102, 151, 135, 76, 1693, 3581, 2305, 40, 931, 1332, 276, 174, 1098, 3582, 328, 362, 1335, 195, 300, 40, 540, 151, 135, 1676, 3583, 1677, 3584, 1324, 808, 1334, 3585, 804, 300, 40, 540, 151, 2315, 538, 362, 3586, 87, 2316, 40, 931, 1332, 3587, 1694, 17, 3588, 3589, 40, 3590, 610, 151, 3591, 175, 300, 40, 540, 151, 1689, 44, 538, 109, 2317, 175, 300, 809, 3592, 151, 3593, 3594, 3595, 539, 3596, 806, 3597, 3598, 1104, 3599, 276, 362, 55, 3600, 1101, 135, 1334, 44, 2318, 3601, 1695, 3602, 1680, 3603, 256, 3604, 327, 1104, 151, 327, 3605, 2, 1331, 1684, 1695, 2309, 276, 174, 1336, 931, 1324, 80, 3606, 3607, 934, 935, 3608, 3, 329, 2314, 807, 2, 17, 3609, 3610, 539, 3611, 135, 810, 2282, 1105, 80, 1323, 1696, 2312, 44, 2318, 1684, 1695, 1697, 3, 17, 2319, 40, 151, 3612, 3613, 3614, 1337, 174, 2, 1698, 2320, 1338, 935, 1104, 151, 276, 174, 1337, 174, 109, 151, 1696, 3615, 194, 1699, 932, 300, 3, 329, 55, 3616, 135, 55, 610, 1099, 2, 1336, 3617, 17, 2319, 40, 151, 811, 1339, 692, 328, 3618, 1689, 44, 151, 1102, 87, 17, 2321, 2313, 1105, 3]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 686\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 521\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 165\n",
      "단어 집합에서 희귀 단어의 비율: 75.94752186588921\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 49.666348903717825\n"
     ]
    }
   ],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 600\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input)\n",
    "tar_tokenizer.fit_on_texts(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 20, 3, 58, 59, 60, 61, 62, 63, 21, 3, 64, 65, 66], [1, 167, 67, 168, 169, 68, 170, 171], [1, 172, 173, 174, 175, 176, 177], [1, 178, 179, 69, 70, 180, 181, 182, 183, 71], [1, 184, 185, 186, 187, 188, 189, 190]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "print(decoder_input_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 50, 128)      768000      input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, 50, 256), (N 394240      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  [(None, 50, 256), (N 525312      lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 128)    76800       input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  [(None, 50, 256), (N 525312      lstm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  [(None, None, 256),  394240      embedding_7[0][0]                \n",
      "                                                                 lstm_14[0][1]                    \n",
      "                                                                 lstm_14[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 600)    154200      lstm_15[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,838,104\n",
      "Trainable params: 2,838,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x000001FC8B550288>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x000001FC8B550288>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x000001FC8B550288>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 50, 128)      768000      input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, 50, 256), (N 394240      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  [(None, 50, 256), (N 525312      lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 128)    76800       input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  [(None, 50, 256), (N 525312      lstm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  [(None, None, 256),  394240      embedding_7[0][0]                \n",
      "                                                                 lstm_14[0][1]                    \n",
      "                                                                 lstm_14[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_14[0][0]                    \n",
      "                                                                 lstm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_15[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 600)    307800      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,123,032\n",
      "Trainable params: 3,123,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 2 samples\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 50s 521ms/sample - loss: 5.8158 - val_loss: 5.5542\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 40s 420ms/sample - loss: 5.2818 - val_loss: 5.7258\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 40s 421ms/sample - loss: 5.0032 - val_loss: 5.3767\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 40s 421ms/sample - loss: 4.7923 - val_loss: 5.2933\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 41s 422ms/sample - loss: 4.7268 - val_loss: 5.3977\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 41s 428ms/sample - loss: 4.5618 - val_loss: 5.7843\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 41s 425ms/sample - loss: 4.3941 - val_loss: 5.1142\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 42s 436ms/sample - loss: 4.2711 - val_loss: 4.7553\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 41s 424ms/sample - loss: 4.1053 - val_loss: 4.4547\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 41s 427ms/sample - loss: 4.1451 - val_loss: 4.3405\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 41s 425ms/sample - loss: 3.9872 - val_loss: 5.2422\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 41s 423ms/sample - loss: 3.8098 - val_loss: 4.3689\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 41s 427ms/sample - loss: 3.6777 - val_loss: 4.2614\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 41s 424ms/sample - loss: 3.5713 - val_loss: 3.9998\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 42s 432ms/sample - loss: 3.4102 - val_loss: 4.3242\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 41s 426ms/sample - loss: 3.5843 - val_loss: 5.1340\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 41s 425ms/sample - loss: 3.8220 - val_loss: 4.2455\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train,\n",
    "                    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                    batch_size = 2, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x000001FC8B550288>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x000001FC8B550288>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x000001FC8B550288>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            sentence = sentence + src_index_to_word[i]+' '\n",
    "    return sentence\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            sentence = sentence + tar_index_to_word[i] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  오갔다 이 날 에디슨 ev 종가 2만원 으로 올해 3월 과 비교 하면 10 배 이상 급등 가격 지난 3분 기 말 기준 에디슨 ev 최대 주주 에너지 솔루션 즈 16 67 에너지 솔루션 즈 의 최대 주주 강 영 권 대표 98 70 출자 자 4 명 포함 다 \n",
      "실제 요약문 : 박자 에디슨 모터 스 ‘ 추가 부실 꺼냈다 \n",
      "예측 요약문 : \n",
      "\n",
      "\n",
      "원문 :  \n",
      "실제 요약문 : 오늘 날씨 7일 동해안 비 또는 눈 \n",
      "예측 요약문 :  인천 의료 원 이재명\n",
      "\n",
      "\n",
      "원문 :  year “ because there were so many orders this year next year s orders could fall by some 25 percent ” said a spokesperson for a shipbuilding company “ but still the number of orders won t be that bad compared to orders received in the past five years ” \n",
      "실제 요약문 : recovery lifts all boats in shipbuilding \n",
      "예측 요약문 :  식\n",
      "\n",
      "\n",
      "원문 :  도입 뜻 같이 하며 다당제 가능한 선거 제 개혁 함께해 나가겠다 고 밝혔습니다 이어 국민 현실 청년 불안한 미래 답 하는 선거 돼야 한다 며 공적 연금 개혁 기후 위기 대응 양극화 불평등 해소 대책 같은 미래 정책 놓고 선의 경쟁 해야 한다 고 덧붙였습니다 사진 국회 사진기 자단 연합뉴스 \n",
      "실제 요약문 : 안철수 양 당 체제 경종 결선투표제 공감 대 \n",
      "예측 요약문 :  개발\n",
      "\n",
      "\n",
      "원문 :  ” 했다 지난달 미래에셋 그룹 전면 적 조직개편 통해 전문 경영인 체제 구축 본격 화했는데 이번 승진 인사 그 연 장선 있다는 것 미래에셋 관계자 “ 앞 증권 외 다른 계 열사 들 전문 경영인 출신 회장 들 독립 적 경영 하는 체제 전환 될 가능성 있다 ” 고 했다 \n",
      "실제 요약문 : 미래에셋 증권 최현 수석 부회장 회장 승진 \n",
      "예측 요약문 :  식 식\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"원문 : \",seq2text(encoder_input_train[i]))\n",
    "    print(\"실제 요약문 :\",seq2summary(decoder_input_train[i]))\n",
    "    print(\"예측 요약문 :\",decode_sequence(encoder_input_train[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt, Kkma\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['contents'].str.len() >= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "\n",
    "def text2sentence (text) :\n",
    "    #print('\\n------------\\n',text,'\\n-------------\\n')\n",
    "    sentence = kkma.sentences(text)\n",
    "    for i in range(len(sentence)):\n",
    "        if len(sentence[i]) <= 10:\n",
    "            #print(sentence[i-1], '  ||  ',sentence[i],'\\n\\n')\n",
    "            sentence[i-1] +=(' '+sentence[i])\n",
    "            sentence[i] = ''\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>분야</th>\n",
       "      <th>s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'위안부 다큐' 英감독 \"더 많이 알려져야 하는 보편적 문제\"</td>\n",
       "      <td>기사내용 요약'이용수 할머니 밀착취재 다큐' 낸시 로버츠 英감독이 할머니 \"위안부 ...</td>\n",
       "      <td>정치</td>\n",
       "      <td>[기사내용 요약' 이용수 할머니 밀착 취재 다큐' 낸 시 로버츠 英 감독이 할머니 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“조국·이재명 가족이라면?”…이재명 ‘김건희 무혐의’ 비판 댓글 공유</td>\n",
       "      <td>이재명 더불어민주당 대선후보가 6일 서울 여의도 더불어민주당 당사에서 열린 소상공인...</td>\n",
       "      <td>정치</td>\n",
       "      <td>[이재명 더불어 민주당 대선후보가 6일 서울 여의도 더불어 민주당 당사에서 열린 소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>닻 올린 '김종인 원톱' 선대위…\"민생·정의 회복\"</td>\n",
       "      <td>'윤석열 선대위'의 키를 거머쥔 김종인 위원장, 한층 '독해진' 어조로 문재인 정부...</td>\n",
       "      <td>정치</td>\n",
       "      <td>[' 윤석 열 선대 위' 의 키를 거머쥔 김 종인 위원장, 한층 ' 독 해진' 어조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>민주, 개발이익환수법 당론 채택…이재명 \"169석 힘 보여달라\" 편지</td>\n",
       "      <td>민주당이 정책 의원총회를 열어 개발이익환수법을 당론으로 추진하기로 했습니다. 대장동...</td>\n",
       "      <td>정치</td>\n",
       "      <td>[민주당이 정책 의원총회를 열어 개발이익 환 수법을 당론으로 추진하기로 했습니다.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김병준 \"자유·민주 죽인 文, 더 한 이재명 막아야…그 국가주의·포퓰리즘 끝은 파멸\"</td>\n",
       "      <td>국힘 선대위 출범식서 연설 \"시장·개인자유 확대 '자유주의 철학'이 사회 문제 해법...</td>\n",
       "      <td>정치</td>\n",
       "      <td>[국 힘 선대 위 출범식서 연설 \" 시장· 개인자유 확대 ' 자유주의 철학' 이 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>임혜숙 장관, OECD 회원국에 '과학기술 기반 미래예측' 제안</td>\n",
       "      <td>임혜숙 과학기술정보통신부 장관이 6일 OECD 과학기술정책위원회 콘퍼런스 고위급회담...</td>\n",
       "      <td>과학</td>\n",
       "      <td>[임 혜숙 과학기술정보통신 부 장관이 6일 OECD 과학기술정책위원회 콘퍼런스 고위...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“초봉 6500만원 준다고 하니…우르르” 난리난 ‘이곳’</td>\n",
       "      <td>김용현 당근마켓 공동대표이런 상황에서 ‘업계 최고 대우’를 내건 당근마켓이 승부수는...</td>\n",
       "      <td>과학</td>\n",
       "      <td>[김용 현 당근 마켓 공동대표 이런 상황에서 ‘ 업계 최고 대우 ’를 내건 당근 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>임혜숙 장관, “미래 예측을 통한 국가·사회 문제해결” 강조</td>\n",
       "      <td>OECD 과학기술정책위원회 컨퍼런스 고위급 회담 참가임혜숙 과학기술정보통신부 장관이...</td>\n",
       "      <td>과학</td>\n",
       "      <td>[OECD 과학기술정책위원회 컨퍼런스 고위급 회담 참가 임 혜숙 과학기술정보통신 부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>임혜숙 과기장관, OECD 컨퍼런스서 포용적 기술전환 방안 제시</td>\n",
       "      <td>기사내용 요약과기장관, 'OECD 과학기술정책위원회 컨퍼런스' 온라인 참석\"미래 예...</td>\n",
       "      <td>과학</td>\n",
       "      <td>[기사내용 요약 과기장관, 'OECD 과학기술정책위원회 컨퍼런스' 온라인 참석\" 미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>임혜숙 장관 \"포용적 기술 전환, 과학기술 기반의 미래 예측이 필수적\"</td>\n",
       "      <td>OECD 과학기술정책위서 포용적 기술 전환 방안 제시임혜숙 과학기술정보통신부 장관이...</td>\n",
       "      <td>과학</td>\n",
       "      <td>[OECD 과학기술 정책위서 포용적 기술 전환 방안 제시 임 혜숙 과학기술정보통신 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0                '위안부 다큐' 英감독 \"더 많이 알려져야 하는 보편적 문제\"   \n",
       "1            “조국·이재명 가족이라면?”…이재명 ‘김건희 무혐의’ 비판 댓글 공유   \n",
       "2                      닻 올린 '김종인 원톱' 선대위…\"민생·정의 회복\"   \n",
       "3            민주, 개발이익환수법 당론 채택…이재명 \"169석 힘 보여달라\" 편지   \n",
       "4   김병준 \"자유·민주 죽인 文, 더 한 이재명 막아야…그 국가주의·포퓰리즘 끝은 파멸\"   \n",
       "..                                              ...   \n",
       "15              임혜숙 장관, OECD 회원국에 '과학기술 기반 미래예측' 제안   \n",
       "16                  “초봉 6500만원 준다고 하니…우르르” 난리난 ‘이곳’   \n",
       "17                임혜숙 장관, “미래 예측을 통한 국가·사회 문제해결” 강조   \n",
       "18              임혜숙 과기장관, OECD 컨퍼런스서 포용적 기술전환 방안 제시   \n",
       "19          임혜숙 장관 \"포용적 기술 전환, 과학기술 기반의 미래 예측이 필수적\"   \n",
       "\n",
       "                                             contents  분야  \\\n",
       "0   기사내용 요약'이용수 할머니 밀착취재 다큐' 낸시 로버츠 英감독이 할머니 \"위안부 ...  정치   \n",
       "1   이재명 더불어민주당 대선후보가 6일 서울 여의도 더불어민주당 당사에서 열린 소상공인...  정치   \n",
       "2   '윤석열 선대위'의 키를 거머쥔 김종인 위원장, 한층 '독해진' 어조로 문재인 정부...  정치   \n",
       "3   민주당이 정책 의원총회를 열어 개발이익환수법을 당론으로 추진하기로 했습니다. 대장동...  정치   \n",
       "4   국힘 선대위 출범식서 연설 \"시장·개인자유 확대 '자유주의 철학'이 사회 문제 해법...  정치   \n",
       "..                                                ...  ..   \n",
       "15  임혜숙 과학기술정보통신부 장관이 6일 OECD 과학기술정책위원회 콘퍼런스 고위급회담...  과학   \n",
       "16  김용현 당근마켓 공동대표이런 상황에서 ‘업계 최고 대우’를 내건 당근마켓이 승부수는...  과학   \n",
       "17  OECD 과학기술정책위원회 컨퍼런스 고위급 회담 참가임혜숙 과학기술정보통신부 장관이...  과학   \n",
       "18  기사내용 요약과기장관, 'OECD 과학기술정책위원회 컨퍼런스' 온라인 참석\"미래 예...  과학   \n",
       "19  OECD 과학기술정책위서 포용적 기술 전환 방안 제시임혜숙 과학기술정보통신부 장관이...  과학   \n",
       "\n",
       "                                                   s1  \n",
       "0   [기사내용 요약' 이용수 할머니 밀착 취재 다큐' 낸 시 로버츠 英 감독이 할머니 ...  \n",
       "1   [이재명 더불어 민주당 대선후보가 6일 서울 여의도 더불어 민주당 당사에서 열린 소...  \n",
       "2   [' 윤석 열 선대 위' 의 키를 거머쥔 김 종인 위원장, 한층 ' 독 해진' 어조...  \n",
       "3   [민주당이 정책 의원총회를 열어 개발이익 환 수법을 당론으로 추진하기로 했습니다.,...  \n",
       "4   [국 힘 선대 위 출범식서 연설 \" 시장· 개인자유 확대 ' 자유주의 철학' 이 사...  \n",
       "..                                                ...  \n",
       "15  [임 혜숙 과학기술정보통신 부 장관이 6일 OECD 과학기술정책위원회 콘퍼런스 고위...  \n",
       "16  [김용 현 당근 마켓 공동대표 이런 상황에서 ‘ 업계 최고 대우 ’를 내건 당근 마...  \n",
       "17  [OECD 과학기술정책위원회 컨퍼런스 고위급 회담 참가 임 혜숙 과학기술정보통신 부...  \n",
       "18  [기사내용 요약 과기장관, 'OECD 과학기술정책위원회 컨퍼런스' 온라인 참석\" 미...  \n",
       "19  [OECD 과학기술 정책위서 포용적 기술 전환 방안 제시 임 혜숙 과학기술정보통신 ...  \n",
       "\n",
       "[88 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['s1'] = df2['contents'].apply(lambda x: text2sentence(x))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def cleansing(x):\\n    result = []\\n    for sentence in x:\\n        tokens = okt.nouns(sentence)\\n        for i in tokens :\\n            if i not in stopwords:\\n                result.append(i)\\n    if len(result) >= 3:\\n        return ' '.join(result)\\n    else :\\n        return None\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt =Okt()\n",
    "\n",
    "stopwords = ['머니투데이', '연합뉴스', '데일리', '동아일보', '중앙일보',\n",
    "            '조선일보', '기자']\n",
    "\n",
    "def cleansing(sentences):\n",
    "    nouns = []\n",
    "    for sentence in sentences :\n",
    "        if sentence is not '':\n",
    "            nouns.append(' '.join([noun for noun in okt.nouns(str(sentence))\n",
    "                                  if noun not in stopwords and len(noun) > 1]))\n",
    "    return nouns\n",
    "'''def cleansing(x):\n",
    "    result = []\n",
    "    for sentence in x:\n",
    "        tokens = okt.nouns(sentence)\n",
    "        for i in tokens :\n",
    "            if i not in stopwords:\n",
    "                result.append(i)\n",
    "    if len(result) >= 3:\n",
    "        return ' '.join(result)\n",
    "    else :\n",
    "        return None'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OECD 과학기술 정책위서 포용적 기술 전환 방안 제시 임 혜숙 과학기술정보통신 부 장관이 6일 경제협력개발기구 (OECD) 과학기술정책위원회 (CSTP) 콘퍼런스 고위급 회담에 참가했다.',\n",
       " \"( 과기 정통부 제공) © 뉴스 1( 서울= 뉴스 1) 윤지원 기자 = 임 혜숙 과학기술정보통신 부 장관이 ' 미래 예측을 통한 국가· 사회 문제 해결' 을 포용적 기술 전환을 위한 핵심 정책 방향으로 제시했다.6\",\n",
       " '일 임 장관은 경제협력개발기구 (OECD) 과학기술정책위원회 (CSTP) 콘퍼런스 고위급 회담에 참가해 이 같은 우리나라의 제 5차 과학기술 기본계획 수립 방향을 소개했다.',\n",
       " '임 장관은 이번 회담에서 \" 사회 전 영역에서 복잡성, 다양성, 불확실성이 높아 지는 상황에서 과학기술 기반의 미래 예측이 필수적\" 이라며 \" 바람직한 정책 성과 목표 설정, 정책 수단의 다양화, 폭넓은 주체의 참여 보장이 중요하다\" 고 강조했다.',\n",
       " '이날 콘퍼런스는 포용적 기술 전환을 주제로 개최됐다.',\n",
       " '우리나라를 비롯해 이탈리아, 포르투 갈, 영국 등 유럽연합 (EU) 장· 차관급 인사와 연구· 산업· 노동계 대표들이 참석해 기술과 사회가 함께 갈 수 있는 방안을 논의했다.',\n",
       " '과기 정통부 관계자는 \" 임 장관은 OECD 회원국들이 직면한 도전 과제가 상호 연계돼 있는 만큼 지속적으로 소통하고 협력 하자고 제언했다\" 고 밝혔다.']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = df2['s1'].values[87]\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과학기술 정책 위서 용적 기술 전환 방안 제시 혜숙 과학기술 정보 통신 장관 협력 과학기술 정책 위원회 콘퍼런스 고위 회담 참가',\n",
       " '과기 정통부 제공 뉴스 서울 뉴스 윤지 혜숙 과학기술 정보 통신 장관 미래 예측 통한 국가 사회 문제 해결 용적 기술 전환 핵심 정책 방향 제시',\n",
       " '장관 협력 과학기술 정책 위원회 콘퍼런스 고위 회담 참가 우리나라 과학기술 기본 계획 수립 방향 소개',\n",
       " '장관 이번 회담 사회 영역 복잡 다양성 불확실 상황 과학기술 기반 미래 예측 필수 라며 정책 성과 목표 설정 정책 수단 다양 주체 참여 보장 강조',\n",
       " '콘퍼런스 용적 기술 전환 주제 개최',\n",
       " '우리나라 비롯 이탈리아 포르투 영국 유럽연합 차관 인사 연구 산업 노동계 대표 참석 기술 사회 방안 논의',\n",
       " '과기 정통부 관계자 장관 회원 직면 도전 과제 상호 만큼 지속 소통 협력 하자 제언']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = cleansing(s1)\n",
    "\n",
    "'''for i in df['s1']:\n",
    "    sentence = cleansing(i)\n",
    "    if sentence is not None:\n",
    "        cleaned.append(cleansing(i))'''\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = TfidfVectorizer()\n",
    "cnt_vec = CountVectorizer()\n",
    "graph_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_sentGraph(x):\n",
    "    tfd_mat = tfd.fit_transform(x).toarray()\n",
    "    gs = np.dot(tfd_mat, tfd_mat.T)\n",
    "    return gs\n",
    "\n",
    "sent_graph = mk_sentGraph(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_wordsGraph(x):\n",
    "    cnt_vec_mat = normalize(cnt_vec.fit_transform(x).toarray().astype(float), axis =0)\n",
    "    voca = cnt_vec.vocabulary_\n",
    "    return np.dot(cnt_vec_mat.T, cnt_vec_mat), {voca[word] : word for word in voca}\n",
    "\n",
    "words_graph, idx2word = mk_wordsGraph(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: '과학기술',\n",
       " 57: '정책',\n",
       " 47: '위서',\n",
       " 45: '용적',\n",
       " 11: '기술',\n",
       " 55: '전환',\n",
       " 24: '방안',\n",
       " 60: '제시',\n",
       " 79: '혜숙',\n",
       " 56: '정보',\n",
       " 71: '통신',\n",
       " 54: '장관',\n",
       " 78: '협력',\n",
       " 48: '위원회',\n",
       " 70: '콘퍼런스',\n",
       " 3: '고위',\n",
       " 80: '회담',\n",
       " 67: '참가',\n",
       " 4: '과기',\n",
       " 58: '정통부',\n",
       " 59: '제공',\n",
       " 14: '뉴스',\n",
       " 34: '서울',\n",
       " 50: '윤지',\n",
       " 23: '미래',\n",
       " 44: '예측',\n",
       " 72: '통한',\n",
       " 8: '국가',\n",
       " 30: '사회',\n",
       " 22: '문제',\n",
       " 76: '해결',\n",
       " 77: '핵심',\n",
       " 25: '방향',\n",
       " 46: '우리나라',\n",
       " 10: '기본',\n",
       " 2: '계획',\n",
       " 40: '수립',\n",
       " 37: '소개',\n",
       " 51: '이번',\n",
       " 43: '영역',\n",
       " 27: '복잡',\n",
       " 16: '다양성',\n",
       " 28: '불확실',\n",
       " 33: '상황',\n",
       " 9: '기반',\n",
       " 74: '필수',\n",
       " 19: '라며',\n",
       " 36: '성과',\n",
       " 21: '목표',\n",
       " 35: '설정',\n",
       " 39: '수단',\n",
       " 15: '다양',\n",
       " 63: '주체',\n",
       " 69: '참여',\n",
       " 26: '보장',\n",
       " 0: '강조',\n",
       " 62: '주제',\n",
       " 1: '개최',\n",
       " 29: '비롯',\n",
       " 52: '이탈리아',\n",
       " 73: '포르투',\n",
       " 42: '영국',\n",
       " 49: '유럽연합',\n",
       " 66: '차관',\n",
       " 53: '인사',\n",
       " 41: '연구',\n",
       " 31: '산업',\n",
       " 12: '노동계',\n",
       " 17: '대표',\n",
       " 68: '참석',\n",
       " 13: '논의',\n",
       " 7: '관계자',\n",
       " 81: '회원',\n",
       " 65: '직면',\n",
       " 18: '도전',\n",
       " 5: '과제',\n",
       " 32: '상호',\n",
       " 20: '만큼',\n",
       " 64: '지속',\n",
       " 38: '소통',\n",
       " 75: '하자',\n",
       " 61: '제언'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.9224294879409698,\n",
       " 1: 1.3075117733964707,\n",
       " 2: 1.3647076577550172,\n",
       " 3: 0.7702527081230867,\n",
       " 4: 0.7679751982149844,\n",
       " 5: 0.4412256306702476,\n",
       " 6: 0.4258975438992224}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ranks(graph, d= 0.85) :\n",
    "    A = graph\n",
    "    matrix_size = A.shape[0]\n",
    "    for id in range(matrix_size):\n",
    "        A[id,id] = 0\n",
    "        link_sum = np.sum(A[:,id])\n",
    "        if link_sum != 0:\n",
    "            A[:,id] /= link_sum\n",
    "        A[:,id] *= -d\n",
    "        A[id,id] = 1\n",
    "    B = (1-d) * np.ones((matrix_size,1))\n",
    "    ranks = np.linalg.solve(A,B)\n",
    "    return {idx: r[0] for idx, r in enumerate(ranks)}\n",
    "\n",
    "sent_rank_idx = get_ranks(sent_graph)\n",
    "sent_rank_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sent_rank_idx = sorted(sent_rank_idx,\n",
    "                              key = lambda x : sent_rank_idx[x], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rank_idx = get_ranks(words_graph)\n",
    "sorted_word_rank_idx = sorted(word_rank_idx,\n",
    "                              key = lambda x : word_rank_idx[x], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(sentences):\n",
    "    sent_num =3\n",
    "    summary = []\n",
    "    index = []\n",
    "    for idx in sorted_sent_rank_idx[:sent_num] :\n",
    "        index.append(idx)\n",
    "    index.sort()\n",
    "    \n",
    "    for idx in index:\n",
    "        summary.append(sentences[idx])\n",
    "    for text in summary:\n",
    "        print(text)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OECD 과학기술 정책위서 포용적 기술 전환 방안 제시 임 혜숙 과학기술정보통신 부 장관이 6일 경제협력개발기구 (OECD) 과학기술정책위원회 (CSTP) 콘퍼런스 고위급 회담에 참가했다.\n",
      "\n",
      "\n",
      "( 과기 정통부 제공) © 뉴스 1( 서울= 뉴스 1) 윤지원 기자 = 임 혜숙 과학기술정보통신 부 장관이 ' 미래 예측을 통한 국가· 사회 문제 해결' 을 포용적 기술 전환을 위한 핵심 정책 방향으로 제시했다.6\n",
      "\n",
      "\n",
      "일 임 장관은 경제협력개발기구 (OECD) 과학기술정책위원회 (CSTP) 콘퍼런스 고위급 회담에 참가해 이 같은 우리나라의 제 5차 과학기술 기본계획 수립 방향을 소개했다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
